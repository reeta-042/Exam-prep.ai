# Exam-prep.ai

ü§ñ ExamAI: Your Personal AI Study AssistantExamAI is an intelligent study application designed to help students prepare for exams by transforming their course materials into an interactive learning experience. Users can upload their PDF documents, and the application will leverage a sophisticated AI pipeline to answer questions, generate follow-up queries, and create quizzes based on the provided content.This project is built to tackle the common challenge of studying from poorly formatted or complex academic documents, ensuring that students can get accurate and relevant information from their notes, no matter the format.Chosen Tech StackThe application is built using a modern, powerful stack for AI and web development:‚Ä¢Backend & AI Logic:‚Ä¢Python: The core programming language.‚Ä¢LangChain: The primary framework for orchestrating the AI pipeline, including data loading, chunking, retrieval, and agentic chains.‚Ä¢Google Gemini: The Large Language Model (LLM) used for generating answers, follow-up questions, and quizzes.‚Ä¢Pinecone: A high-performance vector database used to store document embeddings for efficient semantic search.‚Ä¢Sentence-Transformers: Used to create dense vector embeddings of the text chunks.‚Ä¢Frontend:‚Ä¢Streamlit: A Python framework for rapidly building and deploying interactive web applications.‚Ä¢Key Data Processing Libraries:‚Ä¢unstructured[local-inference]: A powerful library for parsing complex and poorly structured PDFs by understanding the document layout.‚Ä¢opencv-python-headless: A dependency for computer vision tasks required by unstructured.Core Technical Decisions ExplainedWhy unstructured[local-inference]?During development, it became clear that standard PDF text extraction libraries (PyPDFLoader, PyMuPDFLoader) failed on certain real-world academic documents. These documents often have complex layouts, multi-column text, embedded tables, and inconsistent formatting, which caused the retrieval system to pull irrelevant chunks of text (e.g., SQL commands instead of a definition for "data").unstructured[local-inference] was chosen to solve this critical problem. Unlike simpler loaders, it doesn't just read text streams; it uses computer vision and layout-parsing models to:1.Understand the visual structure of the page.2.Intelligently identify distinct elements like titles, paragraphs, and lists.3.Extract clean, logically coherent text blocks.This ensures that the text fed into the chunking process is of the highest possible quality, which is the most critical step for accurate retrieval.Chunking Strategy: chunk_size=700, chunk_overlap=120The quality of retrieval is highly dependent on how the source material is chunked. My strategy is designed to create focused, semantically complete chunks:‚Ä¢chunk_size=700: This size is small enough to ensure that each chunk is focused on a single, specific topic or paragraph. This prevents "diluting" the chunk's relevance with unrelated information, making it easier for the retrieval system to find precise answers to specific questions.‚Ä¢chunk_overlap=120: A significant overlap (around 17%) is crucial to maintain context. It ensures that if a sentence or idea is split at the boundary of a chunk, the full context is preserved across adjacent chunks, preventing the loss of important information.This combination balances focus with context, optimizing the chunks for our hybrid retrieval system.Setup and InstallationFollow these steps to set up and run the project locally.1.Clone the Repository:git clone <your-repository-url>
cd <your-repository-directory>
2.Create a Virtual Environment:python -m venv venv
source venv/bin/activate  # On Windows, use `venv\Scripts\activate`
3.Install Dependencies:
Ensure you have the requirements.txt file from the project.pip install -r requirements.txtNote: The installation for unstructured[local-inference] may take some time as it includes several machine learning libraries.4.Set Up API Keys:
The application requires API keys for Google Gemini and Pinecone. Store these securely. The app is configured to use Streamlit Secrets. Create a file at .streamlit/secrets.toml and add your keys:GOOGLE_API_KEY = "YOUR_GOOGLE_API_KEY"
PINECONE_API_KEY = "YOUR_PINECONE_API_KEY"
PINECONE_INDEX_NAME = "your-pinecone-index-name"
5.Run the Application:streamlit run main.pyThe application should now be running and accessible in your web browser.Example Usage and OutputThe user workflow is simple and intuitive:1.The user uploads a PDF document using the sidebar.2.The application processes and indexes the document.3.The user asks a question in the main input area.Example Query:"What is the difference between a primary key and a foreign key?"Expected Output Format:
The application will display the results in a clean, tabbed interface:‚Ä¢üí° Answer Tab:‚Ä¢Main Answer: A direct, comprehensive answer generated by the AI based on the retrieved context from the document.‚Ä¢ü§î Follow-up Questions: A list of suggested questions to help the user explore the topic further.‚Ä¢üìù Quiz Tab:‚Ä¢A multiple-choice quiz is generated based on the topic. Each question is presented clearly, with the answer hidden in an expandable section to encourage active recall.**Question 1:** Which type of key is used to uniquely identify a record in a table?
- A. Foreign Key
- B. Super Key
- C. Primary Key
    
[Show Answer]  <- This is an expandable button
‚Ä¢üîç Retrieved Context Tab:‚Ä¢This tab shows the raw text chunks that were retrieved from the document and used as the context for generating the answer, providing transparency into the AI's process.Limitations and Known Issues‚Ä¢Document Quality Dependency: While unstructured is powerful, the application's performance is still highly dependent on the quality of the source PDF. Extremely degraded, scanned, or poorly formatted documents may still yield suboptimal results.‚Ä¢Computational Cost: The initial processing of a document, especially with unstructured[local-inference], can be computationally intensive and may take time, particularly for large documents.‚Ä¢Hallucination Risk: Like all LLM-based systems, there is a small but inherent risk of the AI generating plausible but incorrect information (hallucinating), especially if the context it receives is ambiguous. The "Retrieved Context" tab is provided to help users verify the source of the information.
